<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docker images for Open Source bigdata/hadoop projects on Flokkr Documentation</title>
    <link>https://flokkr.github.io/docs/</link>
    <description>Recent content in Docker images for Open Source bigdata/hadoop projects on Flokkr Documentation</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 24 Apr 2017 18:36:24 +0200</lastBuildDate>
    
	<atom:link href="https://flokkr.github.io/docs/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>header</title>
      <link>https://flokkr.github.io/docs/_header/</link>
      <pubDate>Mon, 24 Apr 2017 18:36:24 +0200</pubDate>
      
      <guid>https://flokkr.github.io/docs/_header/</guid>
      <description>Flokkr documentation</description>
    </item>
    
    <item>
      <title>Configuration transformer plugin</title>
      <link>https://flokkr.github.io/docs/launcher/envtoconf/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://flokkr.github.io/docs/launcher/envtoconf/</guid>
      <description>Could be activated by CONFIG_TYPE=simple settings, but it&amp;rsquo;s the default.
Every configuration could be defined with environment variables, and they will be converted finally to hadoop xml, properties, conf or other format. The destination format (and the destination file name) is defined with the name of the environment variable according to a naming convention.
The generated files will be saved to the $CONF_DIR directory.
The source code of the converter utility can be found in a separated repository.</description>
    </item>
    
    <item>
      <title>Consul config loading</title>
      <link>https://flokkr.github.io/docs/launcher/consul/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://flokkr.github.io/docs/launcher/consul/</guid>
      <description>Could be activated with CONFIG_TYPE=consul
 The starter script list the configuration file names based on a consul key prefix. All the files will be downloaded from the consul key value store and the application process will be started with consul-template (enable an automatic restart in case of configuration file change)  The source code of the consul based configuration loading and launcher is available at the elek/consul-launcher repository.</description>
    </item>
    
    <item>
      <title>Docker compose based hadoop/spark cluster</title>
      <link>https://flokkr.github.io/docs/runtime/compose/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://flokkr.github.io/docs/runtime/compose/</guid>
      <description> The https://github.com/flokkr/runtime-compose repository contains example configuration to run various type of clusters (eg. Hadoop HA, Hadoop federation, Spark, etc.)
Usually the could be started with
docker-compose up -d  To scale services you can run
docker-compose scale datanode=1  But please note that not all the containers can be scaled up. The master components (such as Hadoop namenode) usually have hardcoded hostnames which avoid the scaling,
Common properties    Topic Solution     Configuration management    Source of config files: docker-compose external environment variable file   Configuration preprocessing: envtoconf (Convert environment variables to configuration formats   Automatic restart on config change: Not supported, docker-compose up is required   Provisioning and scheduling    Multihost support NO   Requirements on the hosts docker daemon and docker-compose   Definition of the containers per host N/A, one docker-compose file for the local host   Scheduling (find hosts with available resource) NO, localhost only   Failover on host crash NO   Scale up/down: Easy with docker-compose scale datanode=3   Multi tenancy (multiple cluster) Partial (from multiple checkout directory, after port adjustment)   Network    Network between containers dedicated network per docker-compose file   DNS YES, handled by the docker network   Service discovery NO (DNS based)   Data locality NO   Availability of the ports Published according to the docker-compose files    </description>
    </item>
    
    <item>
      <title>Installer plugin</title>
      <link>https://flokkr.github.io/docs/launcher/installer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://flokkr.github.io/docs/launcher/installer/</guid>
      <description>Installer plugin could replace built in components
The original products usually unpacked to the /opt directory during the container build (eg. /opt/hadoop, /opt/spark, etc&amp;hellip;). The install plugin deletes the original product directory and replaces it with a newly one downloaded from the internet.
   Name Default Description     INSTALLER_XXX  The value of the environment variable should be an url. If set, the URL will be downloaded and untar-ed to the /opt/xxx directory.</description>
    </item>
    
    <item>
      <title>Kerberos plugin</title>
      <link>https://flokkr.github.io/docs/launcher/kerberos/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://flokkr.github.io/docs/launcher/kerberos/</guid>
      <description>Kerberos plugin downloads/generates kerberos keytabs and ssl key/truststore
Our total UNSECURE kerberos server contains a REST endpoint to download on-the-fly generated kerberos keytabs, java keystores (ssl keystores, trustores). This plugin could be configured to download the files. The plugin also copies krb5.cfg to /etc.
Configuration    Name Default Description     KERBEROS_SERVER krb5 The name of the UNSECURE kerberos server where the REST endpoint is available on :8081   KERBEROS_KEYTABS  Space separated list of keytab names.</description>
    </item>
    
    <item>
      <title>Retry plugin</title>
      <link>https://flokkr.github.io/docs/launcher/retry/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://flokkr.github.io/docs/launcher/retry/</guid>
      <description>The plugin tries to run the entrypoint of the image multiple times. If the process has been exited with non zero exit code, it tries to rerun the command after a sleep. The sleep time increasing with every iteration and the whole process will be stopped anyway after a fix amount of retry. If the process run enough time (60s) the failure counter and sleep time is reseted.
Configuration    Name Default Description     RETRY_NUMBER 10 Number of times the process will be restarted (in case of non-zero exit code   RETRY_NORMAL_RUN_DURATION 60 After this amount of seconds the RETRY_NUMBER counter will be reseted.</description>
    </item>
    
    <item>
      <title>Sleep plugin</title>
      <link>https://flokkr.github.io/docs/launcher/sleep/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://flokkr.github.io/docs/launcher/sleep/</guid>
      <description> SLEEP: sleep for a specified amount of time.    Name Default Description     SLEEP_SECONDS  If set, the sleep bash command will be called with the value of the environment variable. Better to not use this plugin, if possible.    </description>
    </item>
    
  </channel>
</rss>